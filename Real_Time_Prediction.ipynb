{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "rf_classifier = joblib.load('rf_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_angle(point1, point2, point3):\n",
    "    \"\"\" Calculate angle between two lines \"\"\"\n",
    "    if(point1==(0,0) or point2==(0,0) or point3==(0,0)):\n",
    "        return 0\n",
    "    numerator = point2[1] * (point1[0] - point3[0]) + point1[1] * \\\n",
    "                (point3[0] - point2[0]) + point3[1] * (point2[0] - point1[0])\n",
    "    denominator = (point2[0] - point1[0]) * (point1[0] - point3[0]) + \\\n",
    "                (point2[1] - point1[1]) * (point1[1] - point3[1])\n",
    "\n",
    "    try:\n",
    "        ang = math.atan(numerator/denominator)\n",
    "\n",
    "        ang = ang * 180 / math.pi\n",
    "        if ang < 0:\n",
    "            ang = 180 + ang\n",
    "        return ang\n",
    "    except:\n",
    "        return 90.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = 'temp_frames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Function to perform pose estimation and get angles for an image\n",
    "def get_angles():\n",
    "\n",
    "    # Load the temporary frame\n",
    "    temp_frame_path = os.path.join(temp_dir, 'temp_frame.jpg')\n",
    "\n",
    "    # Create a HandLandmarker object.\n",
    "    base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "    options = vision.HandLandmarkerOptions(base_options=base_options, num_hands=2)\n",
    "    detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "        # Create mp.Image from file\n",
    "    image = mp.Image.create_from_file(temp_frame_path)\n",
    "\n",
    "    # Process image\n",
    "    results = detector.detect(image)\n",
    "\n",
    "    hand_landmarks_list = results.hand_landmarks\n",
    "\n",
    "    if hand_landmarks_list:\n",
    "        # Your existing code for extracting angles\n",
    "        image_landmarks = {}\n",
    "        for idx in range(len(hand_landmarks_list)):\n",
    "            hand_landmarks = hand_landmarks_list[idx]\n",
    "\n",
    "            hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "            hand_landmarks_proto.landmark.extend([\n",
    "                landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "            ])\n",
    "\n",
    "            for i, data_point in enumerate(hand_landmarks_proto.landmark):\n",
    "                image_landmarks[i] = (data_point.x, data_point.y)\n",
    "\n",
    "        # Calculate angles between hand landmarks\n",
    "        angle0 = get_angle(image_landmarks[4], image_landmarks[3], image_landmarks[2])\n",
    "        angle1 = get_angle(image_landmarks[3], image_landmarks[2], image_landmarks[1])\n",
    "        angle2 = get_angle(image_landmarks[2], image_landmarks[1], image_landmarks[0])\n",
    "        angle3 = get_angle(image_landmarks[1], image_landmarks[0], image_landmarks[5])\n",
    "        angle4 = get_angle(image_landmarks[8], image_landmarks[7], image_landmarks[6])\n",
    "        angle5 = get_angle(image_landmarks[7], image_landmarks[6], image_landmarks[5])\n",
    "        angle6 = get_angle(image_landmarks[6], image_landmarks[5], image_landmarks[0])\n",
    "        angle7 = get_angle(image_landmarks[12], image_landmarks[11], image_landmarks[10])\n",
    "        angle8 = get_angle(image_landmarks[11], image_landmarks[10], image_landmarks[9])\n",
    "        angle9 = get_angle(image_landmarks[10], image_landmarks[9], image_landmarks[13])\n",
    "        angle10 = get_angle(image_landmarks[16], image_landmarks[15], image_landmarks[14])\n",
    "        angle11 = get_angle(image_landmarks[15], image_landmarks[14], image_landmarks[13])\n",
    "        angle12 = get_angle(image_landmarks[14], image_landmarks[13], image_landmarks[17])\n",
    "        angle13 = get_angle(image_landmarks[20], image_landmarks[19], image_landmarks[18])\n",
    "        angle14 = get_angle(image_landmarks[19], image_landmarks[18], image_landmarks[17])\n",
    "        angle15 = get_angle(image_landmarks[18], image_landmarks[17], image_landmarks[0])\n",
    "\n",
    "        # Return angles as a dictionary\n",
    "        return [angle0, angle1, angle2, angle3, angle4, angle5, angle6, angle7, angle8, angle9,\n",
    "                                            angle10, angle11, angle12, angle13, angle14, angle15]\n",
    "\n",
    "    else:\n",
    "        # Return None if no hand landmarks are detected\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Temporary directory to save the frames\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "while True:\n",
    "    # Capture a frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Save the frame temporarily\n",
    "    cv2.imwrite(os.path.join(temp_dir, 'temp_frame.jpg'), frame)\n",
    "\n",
    "    # Get angles from the current frame\n",
    "    angles = get_angles()\n",
    "\n",
    "    angles_array = np.array(angles, dtype=np.float64)\n",
    "\n",
    "    # Check if angles array contains NaN\n",
    "    if np.isnan(angles_array).any():\n",
    "        print(\"No hand detected. Skipping prediction.\")\n",
    "        continue\n",
    "    \n",
    "    # Convert the list of lists into a NumPy array\n",
    "    angles_array = np.array(angles)\n",
    "    angles_array = angles_array.reshape(1, -1)\n",
    "\n",
    "    # Make predictions using your model\n",
    "\n",
    "    asl_category_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'del': 26, 'space': 27}\n",
    "\n",
    "    # Reverse mapping to get class names from predicted numbers\n",
    "    asl_class_names = {v: k for k, v in asl_category_mapping.items()}\n",
    "\n",
    "    # Make predictions using your model\n",
    "    predictions = rf_classifier.predict(angles_array)\n",
    "\n",
    "    # Map the predicted numbers to class names\n",
    "    predicted_classes = [asl_class_names[prediction] for prediction in predictions]\n",
    "\n",
    "    # Display predictions on the frame\n",
    "    cv2.putText(frame, f'Predicted: {predicted_classes}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with OpenCV\n",
    "    cv2.imshow('ASL Prediction', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
